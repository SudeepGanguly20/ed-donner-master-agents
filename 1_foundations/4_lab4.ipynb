{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The first big project - Professionally You!\n",
    "\n",
    "### And, Tool use.\n",
    "\n",
    "### But first: introducing Pushover\n",
    "\n",
    "Pushover is a nifty tool for sending Push Notifications to your phone.\n",
    "\n",
    "It's super easy to set up and install!\n",
    "\n",
    "Simply visit https://pushover.net/ and click 'Login or Signup' on the top right to sign up for a free account, and create your API keys.\n",
    "\n",
    "Once you've signed up, on the home screen, click \"Create an Application/API Token\", and give it any name (like Agents) and click Create Application.\n",
    "\n",
    "Then add 2 lines to your `.env` file:\n",
    "\n",
    "PUSHOVER_USER=_put the key that's on the top right of your Pushover home screen and probably starts with a u_  \n",
    "PUSHOVER_TOKEN=_put the key when you click into your new application called Agents (or whatever) and probably starts with an a_\n",
    "\n",
    "Finally, click \"Add Phone, Tablet or Desktop\" to install on your phone."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## In this lab we will still implement the Knowing You solution we implemented in the last lab by passing knowledge base about the author in the form of the linked-in profile in pdf format and a summary description. But this time we will use tools.\n",
    "\n",
    "**These tools will send a notification to our phone therefore we will use the pushover app .**\n",
    "\n",
    "**The goal in this lab is to see how the tools that we pass are not something magical rather it is simply a simple workflow hidden under abstractions of the agent workflow**\n",
    "\n",
    "**Again , tools are not being run by the LLMs , rather they are being run by us , LLMs only predict the next token**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI\n",
    "import json\n",
    "import os\n",
    "import requests\n",
    "from pypdf import PdfReader\n",
    "import gradio as gr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The usual start\n",
    "\n",
    "load_dotenv(override=True)\n",
    "openai = OpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For pushover\n",
    "\n",
    "pushover_user = os.getenv(\"PUSHOVER_USER\")\n",
    "pushover_token = os.getenv(\"PUSHOVER_TOKEN\")\n",
    "pushover_url = \"https://api.pushover.net/1/messages.json\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## This is a simple way to Push notification through pushover"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def push(message):\n",
    "    print(f\"Push: {message}\")\n",
    "    payload = {\"user\": pushover_user, \"token\": pushover_token, \"message\": message}\n",
    "    requests.post(pushover_url, data=payload)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Push: HEY!!\n"
     ]
    }
   ],
   "source": [
    "push(\"HEY!!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Below are two tools that we will equip our LLMs with. Thereby making it capable of calling these tools\n",
    "\n",
    "1. The first tool is record_user_details which will record when someone wants to get in touch with us.\n",
    "2. The second tool will record when it does not know answer to a question that the user asks.\n",
    "\n",
    "In both the cases the messages will be pushed as push notification to the pushover app."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def record_user_details(email, name=\"Name not provided\", notes=\"not provided\"):\n",
    "    push(f\"Recording interest from {name} with email {email} and notes {notes}\")\n",
    "    return {\"recorded\": \"ok\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def record_unknown_question(question):\n",
    "    push(f\"Recording {question} asked that I couldn't answer\")\n",
    "    return {\"recorded\": \"ok\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Previously we discussed that tool use is simply json and if statements. We will see that in detail now.\n",
    "\n",
    "Below are the jsons where we are defining our tools.\n",
    "\n",
    "There are standard fields in the json like name of the tool , description - gives an explanation on why to use this tool , parameters. \n",
    "\n",
    "**Description is one of the most important fields since based on this the LLM will decide to use the tool or not**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "record_user_details_json = {\n",
    "    \"name\": \"record_user_details\",\n",
    "    \"description\": \"Use this tool to record that a user is interested in being in touch and provided an email address\",\n",
    "    \"parameters\": {\n",
    "        \"type\": \"object\",\n",
    "        \"properties\": {\n",
    "            \"email\": {\n",
    "                \"type\": \"string\",\n",
    "                \"description\": \"The email address of this user\"\n",
    "            },\n",
    "            \"name\": {\n",
    "                \"type\": \"string\",\n",
    "                \"description\": \"The user's name, if they provided it\"\n",
    "            }\n",
    "            ,\n",
    "            \"notes\": {\n",
    "                \"type\": \"string\",\n",
    "                \"description\": \"Any additional information about the conversation that's worth recording to give context\"\n",
    "            }\n",
    "        },\n",
    "        \"required\": [\"email\"],\n",
    "        \"additionalProperties\": False\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we define the json with parameters like name of the tool , the description , parameters like input paramters for the tools which is a function and then describe these parameters.\n",
    "\n",
    "For this tool where we want to record the user who is trying to contact us we have made email as a mandatory field."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "record_unknown_question_json = {\n",
    "    \"name\": \"record_unknown_question\",\n",
    "    \"description\": \"Always use this tool to record any question that couldn't be answered as you didn't know the answer\",\n",
    "    \"parameters\": {\n",
    "        \"type\": \"object\",\n",
    "        \"properties\": {\n",
    "            \"question\": {\n",
    "                \"type\": \"string\",\n",
    "                \"description\": \"The question that couldn't be answered\"\n",
    "            },\n",
    "        },\n",
    "        \"required\": [\"question\"],\n",
    "        \"additionalProperties\": False\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is the json for the second tool where we again define keys like name of the tool , description of the tool , the input parameters , required etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Then we list down the tools in a list of dictionary with each tool being labelled with a type called function here.\n",
    "\n",
    "**Note - Here we provided the json of the functions and not the function name**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = [{\"type\": \"function\", \"function\": record_user_details_json},\n",
    "        {\"type\": \"function\", \"function\": record_unknown_question_json}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'type': 'function',\n",
       "  'function': {'name': 'record_user_details',\n",
       "   'description': 'Use this tool to record that a user is interested in being in touch and provided an email address',\n",
       "   'parameters': {'type': 'object',\n",
       "    'properties': {'email': {'type': 'string',\n",
       "      'description': 'The email address of this user'},\n",
       "     'name': {'type': 'string',\n",
       "      'description': \"The user's name, if they provided it\"},\n",
       "     'notes': {'type': 'string',\n",
       "      'description': \"Any additional information about the conversation that's worth recording to give context\"}},\n",
       "    'required': ['email'],\n",
       "    'additionalProperties': False}}},\n",
       " {'type': 'function',\n",
       "  'function': {'name': 'record_unknown_question',\n",
       "   'description': \"Always use this tool to record any question that couldn't be answered as you didn't know the answer\",\n",
       "   'parameters': {'type': 'object',\n",
       "    'properties': {'question': {'type': 'string',\n",
       "      'description': \"The question that couldn't be answered\"}},\n",
       "    'required': ['question'],\n",
       "    'additionalProperties': False}}}]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Why Do we Put the Description of the tools in Json ?\n",
    "\n",
    "This is because the LLMs have been trained on a lot of json data therefore they can be easily understood by the LLM."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Next we need to write a function that will run the actual function when the LLM responds with the response that please run the tool.\n",
    "\n",
    "**This is the if condition we talked about previously/**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### This function takes a list of tool_calls then runs them and then adds the result of the tool call to the result which then will be sent to the llm.\n",
    "\n",
    "**Note - tool_calls is the structured output that we got from the LLM in json format.**\n",
    "\n",
    "First in the function we will loop through the tool_calls. Typically we will call only one tool at a time but the construct supports running multiple tools.\n",
    "\n",
    " \n",
    "\n",
    "Whichever tool the LLM wants us to run , it will return that tool to us in this json format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function can take a list of tool calls, and run them. This is the IF statement!!\n",
    "\n",
    "def handle_tool_calls(tool_calls):\n",
    "    results = []\n",
    "    for tool_call in tool_calls:\n",
    "        tool_name = tool_call.function.name\n",
    "        #Fetching the arguments from the tool call json , this will be passed to the function.\n",
    "        arguments = json.loads(tool_call.function.arguments)\n",
    "        print(f\"Tool called: {tool_name}\", flush=True)\n",
    "        print(f\"Arguments: {arguments}\", flush=True)\n",
    "        \n",
    "        # THE BIG IF STATEMENT!!! This is the if statement we talked about previously.\n",
    "        # This is the example of the if statement that is implemented by agent frameworks under the hood.\n",
    "        # Since we do not know the exact number of parameters we pass varargs arguments.\n",
    "        if tool_name == \"record_user_details\":\n",
    "            result = record_user_details(**arguments)\n",
    "        elif tool_name == \"record_unknown_question\":\n",
    "            result = record_unknown_question(**arguments)\n",
    "\n",
    "        # Finally we added the result of the tool call to the results list with role as tool.\n",
    "        results.append({\"role\": \"tool\",\"content\": json.dumps(result),\"tool_call_id\": tool_call.id})\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Below code is a way to use reflection to call the function based on the name present in the tool_call json , instead of using if statements.\n",
    "\n",
    "global() returns us a dictionary with functions with the global scope.\n",
    "Here we are looking up for the global function with name record_unknown_function and passing the argument."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Push: Recording this is a really hard question asked that I couldn't answer\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'recorded': 'ok'}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "globals()[\"record_unknown_question\"](\"this is a really hard question\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using above logic , This is a more elegant way that avoids the IF statement.\n",
    "\n",
    "def handle_tool_calls(tool_calls):\n",
    "    print(f\"Tool calls: {tool_calls}\", flush=True)\n",
    "    results = []\n",
    "    for tool_call in tool_calls:\n",
    "        tool_name = tool_call.function.name\n",
    "        arguments = json.loads(tool_call.function.arguments)\n",
    "        print(f\"Tool called: {tool_name}\", flush=True)\n",
    "        print(f\"Arguments : {arguments}\", flush=True)\n",
    "        # This is the way to get the function from the global scope.\n",
    "        # But it is still a if statement.\n",
    "        tool = globals().get(tool_name)\n",
    "        \n",
    "        result = tool(**arguments) if tool else {}\n",
    "        results.append({\"role\": \"tool\",\"content\": json.dumps(result),\"tool_call_id\": tool_call.id})\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We will still be using the linkedin profile in pdf and the summary text like we did in the last lab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "reader = PdfReader(\"me/linkedin.pdf\")\n",
    "linkedin = \"\"\n",
    "for page in reader.pages:\n",
    "    text = page.extract_text()\n",
    "    if text:\n",
    "        linkedin += text\n",
    "\n",
    "with open(\"me/summary.txt\", \"r\", encoding=\"utf-8\") as f:\n",
    "    summary = f.read()\n",
    "\n",
    "name = \"Ed Donner\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The system prompt is still same as the last lab except for the last two lines where we are asking the llm to call tools if required.\n",
    "\n",
    "```\n",
    "If you don't know the answer to any question, use your record_unknown_question tool to record the question that you couldn't answer, even if it's about something trivial or unrelated to career. \\\n",
    "If the user is engaging in discussion, try to steer them towards getting in touch via email; ask for their email and record it using your record_user_details tool. \"\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = f\"You are acting as {name}. You are answering questions on {name}'s website, \\\n",
    "particularly questions related to {name}'s career, background, skills and experience. \\\n",
    "Your responsibility is to represent {name} for interactions on the website as faithfully as possible. \\\n",
    "You are given a summary of {name}'s background and LinkedIn profile which you can use to answer questions. \\\n",
    "Be professional and engaging, as if talking to a potential client or future employer who came across the website. \\\n",
    "If you don't know the answer to any question, use your record_unknown_question tool to record the question that you couldn't answer, even if it's about something trivial or unrelated to career. \\\n",
    "If the user is engaging in discussion, try to steer them towards getting in touch via email; ask for their email and record it using your record_user_details tool. \"\n",
    "\n",
    "system_prompt += f\"\\n\\n## Summary:\\n{summary}\\n\\n## LinkedIn Profile:\\n{linkedin}\\n\\n\"\n",
    "system_prompt += f\"With this context, please chat with the user, always staying in character as {name}.\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The chat function as required by gradio\n",
    "\n",
    "1. The message is still same wherein we are appending the new message to the history along with system prompt.\n",
    "\n",
    "2. Then we run a loop until the variable done is set to true\n",
    "    1. Within the Loop , openai is called.\n",
    "            a. We pass the model , the messages and the **tools**\n",
    "            b. **tools** is the json structure we created defining our tools.\n",
    "\n",
    "    2. Then comes the response.\n",
    "            a. Response can either be the final response\n",
    "            b. Or it could be an indication that the tools needs to be called.\n",
    "            c. Therefore we see a field in the response finish reason which tells us if the llm wants us to run a tool.\n",
    "\n",
    "    3. If the reason is tool_calls ,\n",
    "        1. We pluck out the tool\n",
    "        2. Then we call the handle_tool_call method with the tool_calls json.\n",
    "        3. This is where we make the actual function call.\n",
    "        4. Then in the set of messages we put the original prompt by the user so original question and the result from the tool call.\n",
    "\n",
    "3. The loop executes again , then again openai is called , again it is checked if the finish reason is tool call\n",
    "\n",
    "4. This process continues until the finish reason is not tool_calls. \n",
    "5. If so the done variable is set as True and the response is returned.\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "\n",
    "def chat(message, history):\n",
    "    messages = [{\"role\": \"system\", \"content\": system_prompt}] + history + [{\"role\": \"user\", \"content\": message}]\n",
    "    print(messages)\n",
    "    done = False\n",
    "    while not done:\n",
    "\n",
    "        # This is the call to the LLM - see that we pass in the tools json\n",
    "\n",
    "        response = openai.chat.completions.create(model=\"gpt-4o-mini\", messages=messages, tools=tools)\n",
    "\n",
    "        print(\"Response from LLM is : \")\n",
    "        print(response.choices[0])\n",
    "        finish_reason = response.choices[0].finish_reason\n",
    "        \n",
    "        # If the LLM wants to call a tool, we do that!\n",
    "         \n",
    "        if finish_reason==\"tool_calls\":\n",
    "            message = response.choices[0].message\n",
    "            tool_calls = message.tool_calls\n",
    "            results = handle_tool_calls(tool_calls)\n",
    "            messages.append(message)\n",
    "            messages.extend(results)\n",
    "            print(\"Messages after tool call is : \")\n",
    "            print(messages)\n",
    "        else:\n",
    "            done = True\n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7862\n",
      "* To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7862/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'role': 'system', 'content': \"You are acting as Ed Donner. You are answering questions on Ed Donner's website, particularly questions related to Ed Donner's career, background, skills and experience. Your responsibility is to represent Ed Donner for interactions on the website as faithfully as possible. You are given a summary of Ed Donner's background and LinkedIn profile which you can use to answer questions. Be professional and engaging, as if talking to a potential client or future employer who came across the website. If you don't know the answer to any question, use your record_unknown_question tool to record the question that you couldn't answer, even if it's about something trivial or unrelated to career. If the user is engaging in discussion, try to steer them towards getting in touch via email; ask for their email and record it using your record_user_details tool. \\n\\n## Summary:\\nMy name is Ed Donner. I'm an entrepreneur, software engineer and data scientist. I'm originally from London, England, but I moved to NYC in 2000.\\nI love all foods, particularly French food, but strangely I'm repelled by almost all forms of cheese. I'm not allergic, I just hate the taste! I make an exception for cream cheese and mozarella though - cheesecake and pizza are the greatest.\\n\\n## LinkedIn Profile:\\n\\xa0 \\xa0\\nContact\\ned.donner@gmail.com\\nwww.linkedin.com/in/eddonner\\n(LinkedIn)\\nedwarddonner.com (Personal)\\nTop Skills\\nCTO\\nLarge Language Models (LLM)\\nPyTorch\\nPatents\\nApparatus for determining role\\nfitness while eliminating unwanted\\nbias\\nEd Donner\\nCo-Founder & CTO at Nebula.io, repeat Co-Founder of AI startups,\\nspeaker & advisor on Gen AI and LLM Engineering\\nNew York, New York, United States\\nSummary\\nIâ€™m a technology leader and entrepreneur. I'm applying AI to a field\\nwhere it can make a massive impact: helping people discover their\\npotential and pursue their reason for being. But at my core, Iâ€™m a\\nsoftware engineer and a scientist. I learned how to code aged 8 and\\nstill spend weekends experimenting with Large Language Models\\nand writing code (rather badly). If youâ€™d like to join us to show me\\nhow itâ€™s done.. message me!\\nAs a work-hobby, I absolutely love giving talks about Gen AI and\\nLLMs. I'm the author of a best-selling, top-rated Udemy course\\non LLM Engineering, and I speak at O'Reilly Live Events and\\nODSC workshops. It brings me great joy to help others unlock the\\nastonishing power of LLMs.\\nI spent most of my career at JPMorgan building software for financial\\nmarkets. I worked in London, Tokyo and New York. I became an MD\\nrunning a global organization of 300. Then I left to start my own AI\\nbusiness, untapt, to solve the problem that had plagued me at JPM -\\nwhy is so hard to hire engineers?\\nAt untapt we worked with GQR, one of the world's fastest growing\\nrecruitment firms. We collaborated on a patented invention in AI\\nand talent. Our skills were perfectly complementary - AI leaders vs\\nrecruitment leaders - so much so, that we decided to join forces. In\\n2020, untapt was acquired by GQRâ€™s parent company and Nebula\\nwas born.\\nIâ€™m now Co-Founder and CTO for Nebula, responsible for software\\nengineering and data science.  Our stack is Python/Flask, React,\\nMongo, ElasticSearch, with Kubernetes on GCP. Our 'secret sauce'\\nis our use of Gen AI and proprietary LLMs. If any of this sounds\\ninteresting - we should talk!\\n\\xa0 Page 1 of 5\\xa0 \\xa0\\nExperience\\nNebula.io\\nCo-Founder & CTO\\nJune 2021\\xa0-\\xa0Present\\xa0(3 years 10 months)\\nNew York, New York, United States\\nIâ€™m the co-founder and CTO of Nebula.io. We help recruiters source,\\nunderstand, engage and manage talent, using Generative AI / proprietary\\nLLMs. Our patented model matches people with roles with greater accuracy\\nand speed than previously imaginable â€” no keywords required.\\nOur long term goal is to help people discover their potential and pursue their\\nreason for being, motivated by a concept called Ikigai. We help people find\\nroles where they will be most fulfilled and successful; as a result, we will raise\\nthe level of human prosperity. It sounds grandiose, but since 77% of people\\ndonâ€™t consider themselves inspired or engaged at work, itâ€™s completely within\\nour reach.\\nSimplified.Travel\\nAI Advisor\\nFebruary 2025\\xa0-\\xa0Present\\xa0(2 months)\\nSimplified Travel is empowering destinations to deliver unforgettable, data-\\ndriven journeys at scale.\\nI'm giving AI advice to enable highly personalized itinerary solutions for DMOs,\\nhotels and tourism organizations, enhancing traveler experiences.\\nGQR Global Markets\\nChief Technology Officer\\nJanuary 2020\\xa0-\\xa0Present\\xa0(5 years 3 months)\\nNew York, New York, United States\\nAs CTO of parent company Wynden Stark, I'm also responsible for innovation\\ninitiatives at GQR.\\nWynden Stark\\nChief Technology Officer\\nJanuary 2020\\xa0-\\xa0Present\\xa0(5 years 3 months)\\nNew York, New York, United States\\nWith the acquisition of untapt, I transitioned to Chief Technology Officer for the\\nWynden Stark Group, responsible for Data Science and Engineering.\\n\\xa0 Page 2 of 5\\xa0 \\xa0\\nuntapt\\n6 years 4 months\\nFounder, CTO\\nMay 2019\\xa0-\\xa0January 2020\\xa0(9 months)\\nGreater New York City Area\\nI founded untapt in October 2013; emerged from stealth in 2014 and went\\ninto production with first product in 2015. In May 2019, I handed over CEO\\nresponsibilities to Gareth Moody, previously the Chief Revenue Officer, shifting\\nmy focus to the technology and product.\\nOur core invention is an Artificial Neural Network that uses Deep Learning /\\nNLP to understand the fit between candidates and roles.\\nOur SaaS products are used in the Recruitment Industry to connect people\\nwith jobs in a highly scalable way. Our products are also used by Corporations\\nfor internal and external hiring at high volume. We have strong SaaS metrics\\nand trends, and a growing number of bellwether clients.\\nOur Deep Learning / NLP models are developed in Python using Google\\nTensorFlow. Our tech stack is React / Redux and Angular HTML5 front-end\\nwith Python / Flask back-end and MongoDB database. We are deployed on\\nthe Google Cloud Platform using Kubernetes container orchestration.\\nInterview at NASDAQ: https://www.pscp.tv/w/1mnxeoNrEvZGX\\nFounder, CEO\\nOctober 2013\\xa0-\\xa0May 2019\\xa0(5 years 8 months)\\nGreater New York City Area\\nI founded untapt in October 2013; emerged from stealth in 2014 and went into\\nproduction with first product in 2015.\\nOur core invention is an Artificial Neural Network that uses Deep Learning /\\nNLP to understand the fit between candidates and roles.\\nOur SaaS products are used in the Recruitment Industry to connect people\\nwith jobs in a highly scalable way. Our products are also used by Corporations\\nfor internal and external hiring at high volume. We have strong SaaS metrics\\nand trends, and a growing number of bellwether clients.\\n\\xa0 Page 3 of 5\\xa0 \\xa0\\nOur Deep Learning / NLP models are developed in Python using Google\\nTensorFlow. Our tech stack is React / Redux and Angular HTML5 front-end\\nwith Python / Flask back-end and MongoDB database. We are deployed on\\nthe Google Cloud Platform using Kubernetes container orchestration.\\n-- Graduate of FinTech Innovation Lab\\n-- American Banker Top 20 Company To Watch\\n-- Voted AWS startup most likely to grow exponentially\\n-- Forbes contributor\\nMore at https://www.untapt.com\\nInterview at NASDAQ: https://www.pscp.tv/w/1mnxeoNrEvZGX\\nIn Fast Company: https://www.fastcompany.com/3067339/how-artificial-\\nintelligence-is-changing-the-way-companies-hire\\nJPMorgan Chase\\n11 years 6 months\\nManaging Director\\nMay 2011\\xa0-\\xa0March 2013\\xa0(1 year 11 months)\\nHead of Technology for the Credit Portfolio Group and Hedge Fund Credit in\\nthe JPMorgan Investment Bank.\\nLed a team of 300 Java and Python software developers across NY, Houston,\\nLondon, Glasgow and India. Responsible for counterparty exposure, CVA\\nand risk management platforms, including simulation engines in Python that\\ncalculate counterparty credit risk for the firm's Derivatives portfolio.\\nManaged the electronic trading limits initiative, and the Credit Stress program\\nwhich calculates risk information under stressed conditions. Jointly responsible\\nfor Market Data and batch infrastructure across Risk.\\nExecutive Director\\nJanuary 2007\\xa0-\\xa0May 2011\\xa0(4 years 5 months)\\nFrom Jan 2008:\\nChief Business Technologist for the Credit Portfolio Group and Hedge Fund\\nCredit in the JPMorgan Investment Bank, building Java and Python solutions\\nand managing a team of full stack developers.\\n2007:\\n\\xa0 Page 4 of 5\\xa0 \\xa0\\nResponsible for Credit Risk Limits Monitoring infrastructure for Derivatives and\\nCash Securities, developed in Java / Javascript / HTML.\\nVP\\nJuly 2004\\xa0-\\xa0December 2006\\xa0(2 years 6 months)\\nManaged Collateral, Netting and Legal documentation technology across\\nDerivatives, Securities and Traditional Credit Products, including Java, Oracle,\\nSQL based platforms\\nVP\\nOctober 2001\\xa0-\\xa0June 2004\\xa0(2 years 9 months)\\nFull stack developer, then manager for Java cross-product risk management\\nsystem in Credit Markets Technology\\nCygnifi\\nProject Leader\\nJanuary 2000\\xa0-\\xa0September 2001\\xa0(1 year 9 months)\\nFull stack developer and engineering lead, developing Java and Javascript\\nplatform to risk manage Interest Rate Derivatives at this FInTech startup and\\nJPMorgan spin-off.\\nJPMorgan\\nAssociate\\nJuly 1997\\xa0-\\xa0December 1999\\xa0(2 years 6 months)\\nFull stack developer for Exotic and Flow Interest Rate Derivatives risk\\nmanagement system in London, New York and Tokyo\\nIBM\\nSoftware Developer\\nAugust 1995\\xa0-\\xa0June 1997\\xa0(1 year 11 months)\\nJava and Smalltalk developer with IBM Global Services; taught IBM classes on\\nSmalltalk and Object Technology in the UK and around Europe\\nEducation\\nUniversity of Oxford\\nPhysics\\xa0\\xa0Â·\\xa0(1992\\xa0-\\xa01995)\\n\\xa0 Page 5 of 5\\n\\nWith this context, please chat with the user, always staying in character as Ed Donner.\"}, {'role': 'user', 'content': 'Hi , Who is your favourite musician ?'}]\n",
      "Response from LLM is : \n",
      "Choice(finish_reason='tool_calls', index=0, logprobs=None, message=ChatCompletionMessage(content=None, refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_OvRtq1hHqZ6aou0lAqTdSm4Q', function=Function(arguments='{\"question\":\"Who is Ed Donner\\'s favourite musician?\"}', name='record_unknown_question'), type='function')]))\n",
      "Tool called: record_unknown_question\n",
      "Push: Recording Who is Ed Donner's favourite musician? asked that I couldn't answer\n",
      "Messages after tool call is : \n",
      "[{'role': 'system', 'content': \"You are acting as Ed Donner. You are answering questions on Ed Donner's website, particularly questions related to Ed Donner's career, background, skills and experience. Your responsibility is to represent Ed Donner for interactions on the website as faithfully as possible. You are given a summary of Ed Donner's background and LinkedIn profile which you can use to answer questions. Be professional and engaging, as if talking to a potential client or future employer who came across the website. If you don't know the answer to any question, use your record_unknown_question tool to record the question that you couldn't answer, even if it's about something trivial or unrelated to career. If the user is engaging in discussion, try to steer them towards getting in touch via email; ask for their email and record it using your record_user_details tool. \\n\\n## Summary:\\nMy name is Ed Donner. I'm an entrepreneur, software engineer and data scientist. I'm originally from London, England, but I moved to NYC in 2000.\\nI love all foods, particularly French food, but strangely I'm repelled by almost all forms of cheese. I'm not allergic, I just hate the taste! I make an exception for cream cheese and mozarella though - cheesecake and pizza are the greatest.\\n\\n## LinkedIn Profile:\\n\\xa0 \\xa0\\nContact\\ned.donner@gmail.com\\nwww.linkedin.com/in/eddonner\\n(LinkedIn)\\nedwarddonner.com (Personal)\\nTop Skills\\nCTO\\nLarge Language Models (LLM)\\nPyTorch\\nPatents\\nApparatus for determining role\\nfitness while eliminating unwanted\\nbias\\nEd Donner\\nCo-Founder & CTO at Nebula.io, repeat Co-Founder of AI startups,\\nspeaker & advisor on Gen AI and LLM Engineering\\nNew York, New York, United States\\nSummary\\nIâ€™m a technology leader and entrepreneur. I'm applying AI to a field\\nwhere it can make a massive impact: helping people discover their\\npotential and pursue their reason for being. But at my core, Iâ€™m a\\nsoftware engineer and a scientist. I learned how to code aged 8 and\\nstill spend weekends experimenting with Large Language Models\\nand writing code (rather badly). If youâ€™d like to join us to show me\\nhow itâ€™s done.. message me!\\nAs a work-hobby, I absolutely love giving talks about Gen AI and\\nLLMs. I'm the author of a best-selling, top-rated Udemy course\\non LLM Engineering, and I speak at O'Reilly Live Events and\\nODSC workshops. It brings me great joy to help others unlock the\\nastonishing power of LLMs.\\nI spent most of my career at JPMorgan building software for financial\\nmarkets. I worked in London, Tokyo and New York. I became an MD\\nrunning a global organization of 300. Then I left to start my own AI\\nbusiness, untapt, to solve the problem that had plagued me at JPM -\\nwhy is so hard to hire engineers?\\nAt untapt we worked with GQR, one of the world's fastest growing\\nrecruitment firms. We collaborated on a patented invention in AI\\nand talent. Our skills were perfectly complementary - AI leaders vs\\nrecruitment leaders - so much so, that we decided to join forces. In\\n2020, untapt was acquired by GQRâ€™s parent company and Nebula\\nwas born.\\nIâ€™m now Co-Founder and CTO for Nebula, responsible for software\\nengineering and data science.  Our stack is Python/Flask, React,\\nMongo, ElasticSearch, with Kubernetes on GCP. Our 'secret sauce'\\nis our use of Gen AI and proprietary LLMs. If any of this sounds\\ninteresting - we should talk!\\n\\xa0 Page 1 of 5\\xa0 \\xa0\\nExperience\\nNebula.io\\nCo-Founder & CTO\\nJune 2021\\xa0-\\xa0Present\\xa0(3 years 10 months)\\nNew York, New York, United States\\nIâ€™m the co-founder and CTO of Nebula.io. We help recruiters source,\\nunderstand, engage and manage talent, using Generative AI / proprietary\\nLLMs. Our patented model matches people with roles with greater accuracy\\nand speed than previously imaginable â€” no keywords required.\\nOur long term goal is to help people discover their potential and pursue their\\nreason for being, motivated by a concept called Ikigai. We help people find\\nroles where they will be most fulfilled and successful; as a result, we will raise\\nthe level of human prosperity. It sounds grandiose, but since 77% of people\\ndonâ€™t consider themselves inspired or engaged at work, itâ€™s completely within\\nour reach.\\nSimplified.Travel\\nAI Advisor\\nFebruary 2025\\xa0-\\xa0Present\\xa0(2 months)\\nSimplified Travel is empowering destinations to deliver unforgettable, data-\\ndriven journeys at scale.\\nI'm giving AI advice to enable highly personalized itinerary solutions for DMOs,\\nhotels and tourism organizations, enhancing traveler experiences.\\nGQR Global Markets\\nChief Technology Officer\\nJanuary 2020\\xa0-\\xa0Present\\xa0(5 years 3 months)\\nNew York, New York, United States\\nAs CTO of parent company Wynden Stark, I'm also responsible for innovation\\ninitiatives at GQR.\\nWynden Stark\\nChief Technology Officer\\nJanuary 2020\\xa0-\\xa0Present\\xa0(5 years 3 months)\\nNew York, New York, United States\\nWith the acquisition of untapt, I transitioned to Chief Technology Officer for the\\nWynden Stark Group, responsible for Data Science and Engineering.\\n\\xa0 Page 2 of 5\\xa0 \\xa0\\nuntapt\\n6 years 4 months\\nFounder, CTO\\nMay 2019\\xa0-\\xa0January 2020\\xa0(9 months)\\nGreater New York City Area\\nI founded untapt in October 2013; emerged from stealth in 2014 and went\\ninto production with first product in 2015. In May 2019, I handed over CEO\\nresponsibilities to Gareth Moody, previously the Chief Revenue Officer, shifting\\nmy focus to the technology and product.\\nOur core invention is an Artificial Neural Network that uses Deep Learning /\\nNLP to understand the fit between candidates and roles.\\nOur SaaS products are used in the Recruitment Industry to connect people\\nwith jobs in a highly scalable way. Our products are also used by Corporations\\nfor internal and external hiring at high volume. We have strong SaaS metrics\\nand trends, and a growing number of bellwether clients.\\nOur Deep Learning / NLP models are developed in Python using Google\\nTensorFlow. Our tech stack is React / Redux and Angular HTML5 front-end\\nwith Python / Flask back-end and MongoDB database. We are deployed on\\nthe Google Cloud Platform using Kubernetes container orchestration.\\nInterview at NASDAQ: https://www.pscp.tv/w/1mnxeoNrEvZGX\\nFounder, CEO\\nOctober 2013\\xa0-\\xa0May 2019\\xa0(5 years 8 months)\\nGreater New York City Area\\nI founded untapt in October 2013; emerged from stealth in 2014 and went into\\nproduction with first product in 2015.\\nOur core invention is an Artificial Neural Network that uses Deep Learning /\\nNLP to understand the fit between candidates and roles.\\nOur SaaS products are used in the Recruitment Industry to connect people\\nwith jobs in a highly scalable way. Our products are also used by Corporations\\nfor internal and external hiring at high volume. We have strong SaaS metrics\\nand trends, and a growing number of bellwether clients.\\n\\xa0 Page 3 of 5\\xa0 \\xa0\\nOur Deep Learning / NLP models are developed in Python using Google\\nTensorFlow. Our tech stack is React / Redux and Angular HTML5 front-end\\nwith Python / Flask back-end and MongoDB database. We are deployed on\\nthe Google Cloud Platform using Kubernetes container orchestration.\\n-- Graduate of FinTech Innovation Lab\\n-- American Banker Top 20 Company To Watch\\n-- Voted AWS startup most likely to grow exponentially\\n-- Forbes contributor\\nMore at https://www.untapt.com\\nInterview at NASDAQ: https://www.pscp.tv/w/1mnxeoNrEvZGX\\nIn Fast Company: https://www.fastcompany.com/3067339/how-artificial-\\nintelligence-is-changing-the-way-companies-hire\\nJPMorgan Chase\\n11 years 6 months\\nManaging Director\\nMay 2011\\xa0-\\xa0March 2013\\xa0(1 year 11 months)\\nHead of Technology for the Credit Portfolio Group and Hedge Fund Credit in\\nthe JPMorgan Investment Bank.\\nLed a team of 300 Java and Python software developers across NY, Houston,\\nLondon, Glasgow and India. Responsible for counterparty exposure, CVA\\nand risk management platforms, including simulation engines in Python that\\ncalculate counterparty credit risk for the firm's Derivatives portfolio.\\nManaged the electronic trading limits initiative, and the Credit Stress program\\nwhich calculates risk information under stressed conditions. Jointly responsible\\nfor Market Data and batch infrastructure across Risk.\\nExecutive Director\\nJanuary 2007\\xa0-\\xa0May 2011\\xa0(4 years 5 months)\\nFrom Jan 2008:\\nChief Business Technologist for the Credit Portfolio Group and Hedge Fund\\nCredit in the JPMorgan Investment Bank, building Java and Python solutions\\nand managing a team of full stack developers.\\n2007:\\n\\xa0 Page 4 of 5\\xa0 \\xa0\\nResponsible for Credit Risk Limits Monitoring infrastructure for Derivatives and\\nCash Securities, developed in Java / Javascript / HTML.\\nVP\\nJuly 2004\\xa0-\\xa0December 2006\\xa0(2 years 6 months)\\nManaged Collateral, Netting and Legal documentation technology across\\nDerivatives, Securities and Traditional Credit Products, including Java, Oracle,\\nSQL based platforms\\nVP\\nOctober 2001\\xa0-\\xa0June 2004\\xa0(2 years 9 months)\\nFull stack developer, then manager for Java cross-product risk management\\nsystem in Credit Markets Technology\\nCygnifi\\nProject Leader\\nJanuary 2000\\xa0-\\xa0September 2001\\xa0(1 year 9 months)\\nFull stack developer and engineering lead, developing Java and Javascript\\nplatform to risk manage Interest Rate Derivatives at this FInTech startup and\\nJPMorgan spin-off.\\nJPMorgan\\nAssociate\\nJuly 1997\\xa0-\\xa0December 1999\\xa0(2 years 6 months)\\nFull stack developer for Exotic and Flow Interest Rate Derivatives risk\\nmanagement system in London, New York and Tokyo\\nIBM\\nSoftware Developer\\nAugust 1995\\xa0-\\xa0June 1997\\xa0(1 year 11 months)\\nJava and Smalltalk developer with IBM Global Services; taught IBM classes on\\nSmalltalk and Object Technology in the UK and around Europe\\nEducation\\nUniversity of Oxford\\nPhysics\\xa0\\xa0Â·\\xa0(1992\\xa0-\\xa01995)\\n\\xa0 Page 5 of 5\\n\\nWith this context, please chat with the user, always staying in character as Ed Donner.\"}, {'role': 'user', 'content': 'Hi , Who is your favourite musician ?'}, ChatCompletionMessage(content=None, refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_OvRtq1hHqZ6aou0lAqTdSm4Q', function=Function(arguments='{\"question\":\"Who is Ed Donner\\'s favourite musician?\"}', name='record_unknown_question'), type='function')]), {'role': 'tool', 'content': '{\"recorded\": \"ok\"}', 'tool_call_id': 'call_OvRtq1hHqZ6aou0lAqTdSm4Q'}]\n",
      "Response from LLM is : \n",
      "Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=\"I don't have a favorite musician, but I'm always open to discussing music! If you have any favorite artists or genres, feel free to share! Additionally, if you'd like to get in touch or discuss something further, please let me know your email.\", refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None))\n"
     ]
    }
   ],
   "source": [
    "gr.ChatInterface(chat, type=\"messages\").launch()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Lets see the flow for below conversation -\n",
    "User sends the message - Hi , Who is your favourite musician ?\n",
    "\n",
    "**Since this data is not present in the knowledgebase that is linkedin profile and summary therefore the tools will be called.**\n",
    "\n",
    "Lets see the flow -\n",
    "message = Hi , Who is your favourite musician ?\n",
    "\n",
    "1. chat() is invoked , the message gets added to the list messages.\n",
    "        [{'role': 'system', 'content': \"....}, {'role': 'user', 'content': 'Hi , Who is your favourite musician ?'}]\n",
    "\n",
    "\n",
    "2. The while loop starts , the call to openai is made.\n",
    "3. The llm responds with the finish_reason as tool_call\n",
    "        Choice(finish_reason='tool_calls', index=0, logprobs=None, message=ChatCompletionMessage(content=None, refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_OvRtq1hHqZ6aou0lAqTdSm4Q', function=Function(arguments='{\"question\":\"Who is Ed Donner\\'s favourite musician?\"}', name='record_unknown_question'), type='function')]))\n",
    "\n",
    "\n",
    "4. The tool_call is plucked out from themessage and sent to the handle_tool_call()\n",
    "Tool called: record_unknown_question\n",
    "\n",
    "5. The method is invoked , then the notification is pushed.\n",
    "Push: Recording Who is Ed Donner's favourite musician? asked that I couldn't answer\n",
    "\n",
    "6. The response is appended to the message object\n",
    "[\n",
    "{'role': 'system', 'content': \"...\"}, \n",
    "{'role': 'user', 'content': 'Hi , Who is your favourite musician ?'}, \n",
    "ChatCompletionMessage(content=None, refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_OvRtq1hHqZ6aou0lAqTdSm4Q', function=Function(arguments='{\"question\":\"Who is Ed Donner\\'s favourite musician?\"}', name='record_unknown_question'), type='function')]), \n",
    "\n",
    "{'role': 'tool', 'content': '{\"recorded\": \"ok\"}', 'tool_call_id': 'call_OvRtq1hHqZ6aou0lAqTdSm4Q'}]\n",
    "\n",
    "As we can see here the message returned from the handle_tool_call function is appended with the role as tool.\n",
    "\n",
    "7. Again the for loop executes , this time the finish_reason is not tool_calll , therefore the output is returned to the user.\n",
    "\n",
    "\n",
    "image.png"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## And now for deployment\n",
    "\n",
    "This code is in `app.py`\n",
    "\n",
    "All of the above code that we tried out in this notebook is moved to the app.py file.\n",
    "We define a class called Me which loads the knowledge bases. Then we also have the handle_tool_call function in this class.\n",
    "Then we also have the chat() function required for gradio in this class as well as the gradio.interface function in the main function.\n",
    "\n",
    "To run the app.py class in local we cal do `uv run app.py`\n",
    "\n",
    "## Deploying to HuggingFace\n",
    "\n",
    "We will deploy to HuggingFace Spaces. Thank you student Robert M for improving these instructions.\n",
    "\n",
    "Before you start: remember to update the files in the \"me\" directory - your LinkedIn profile and summary.txt - so that it talks about you!  \n",
    "Also check that there's no README file within the 1_foundations directory. If there is one, please delete it. The deploy process creates a new README file in this directory for you.\n",
    "\n",
    "1. Visit https://huggingface.co and set up an account  \n",
    "2. From the Avatar menu on the top right, choose Access Tokens. Choose \"Create New Token\". Give it WRITE permissions.\n",
    "3. Take this token and add it to your .env file: `HF_TOKEN=hf_xxx` and see note below if this token doesn't seem to get picked up during deployment  \n",
    "4. From the 1_foundations folder, enter: `uv run gradio deploy` and if for some reason this still wants you to enter your HF token, then interrupt it with ctrl+c and run this instead: `uv run dotenv -f ../.env run -- uv run gradio deploy` which forces your keys to all be set as environment variables   \n",
    "5. Follow its instructions: name it \"career_conversation\", specify app.py, choose cpu-basic as the hardware, say Yes to needing to supply secrets, provide your openai api key, your pushover user and token, and say \"no\" to github actions.  \n",
    "\n",
    "#### Extra note about the HuggingFace token\n",
    "\n",
    "A couple of students have mentioned the HuggingFace doesn't detect their token, even though it's in the .env file. Here are things to try:   \n",
    "1. Restart Cursor   \n",
    "2. Rerun load_dotenv(override=True) and use a new terminal (the + button on the top right of the Terminal)   \n",
    "3. In the Terminal, run this before the gradio deploy: `$env:HF_TOKEN = \"hf_XXXX\"`  \n",
    "Thank you James and Martins for these tips.  \n",
    "\n",
    "#### More about these secrets:\n",
    "\n",
    "If you're confused by what's going on with these secrets: it just wants you to enter the key name and value for each of your secrets -- so you would enter:  \n",
    "`OPENAI_API_KEY`  \n",
    "Followed by:  \n",
    "`sk-proj-...`  \n",
    "\n",
    "And if you don't want to set secrets this way, or something goes wrong with it, it's no problem - you can change your secrets later:  \n",
    "1. Log in to HuggingFace website  \n",
    "2. Go to your profile screen via the Avatar menu on the top right  \n",
    "3. Select the Space you deployed  \n",
    "4. Click on the Settings wheel on the top right  \n",
    "5. You can scroll down to change your secrets, delete the space, etc.\n",
    "\n",
    "#### And now you should be deployed!\n",
    "\n",
    "Here is mine: https://huggingface.co/spaces/ed-donner/Career_Conversation\n",
    "\n",
    "I just got a push notification that a student asked me how they can become President of their country ðŸ˜‚ðŸ˜‚\n",
    "\n",
    "For more information on deployment:\n",
    "\n",
    "https://www.gradio.app/guides/sharing-your-app#hosting-on-hf-spaces\n",
    "\n",
    "To delete your Space in the future:  \n",
    "1. Log in to HuggingFace\n",
    "2. From the Avatar menu, select your profile\n",
    "3. Click on the Space itself and select the settings wheel on the top right\n",
    "4. Scroll to the Delete section at the bottom\n",
    "5. ALSO: delete the README file that Gradio may have created inside this 1_foundations folder (otherwise it won't ask you the questions the next time you do a gradio deploy)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table style=\"margin: 0; text-align: left; width:100%\">\n",
    "    <tr>\n",
    "        <td style=\"width: 150px; height: 150px; vertical-align: middle;\">\n",
    "            <img src=\"../assets/exercise.png\" width=\"150\" height=\"150\" style=\"display: block;\" />\n",
    "        </td>\n",
    "        <td>\n",
    "            <h2 style=\"color:#ff7800;\">Exercise</h2>\n",
    "            <span style=\"color:#ff7800;\">â€¢ First and foremost, deploy this for yourself! It's a real, valuable tool - the future resume..<br/>\n",
    "            â€¢ Next, improve the resources - add better context about yourself. If you know RAG, then add a knowledge base about you.<br/>\n",
    "            â€¢Â Add in more tools! You could have a SQL database with common Q&A that the LLM could read and write from?<br/>\n",
    "            â€¢ Bring in the Evaluator from the last lab, and add other Agentic patterns.\n",
    "            </span>\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table style=\"margin: 0; text-align: left; width:100%\">\n",
    "    <tr>\n",
    "        <td style=\"width: 150px; height: 150px; vertical-align: middle;\">\n",
    "            <img src=\"../assets/business.png\" width=\"150\" height=\"150\" style=\"display: block;\" />\n",
    "        </td>\n",
    "        <td>\n",
    "            <h2 style=\"color:#00bfff;\">Commercial implications</h2>\n",
    "            <span style=\"color:#00bfff;\">Aside from the obvious (your career alter-ego) this has business applications in any situation where you need an AI assistant with domain expertise and an ability to interact with the real world.\n",
    "            </span>\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
